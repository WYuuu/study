# Table of Contents

* [分布式事务的产生](#分布式事务的产生)
* [分布式事务基础](#分布式事务基础)
  * [分布式CAP怎么理解（争议）](#分布式cap怎么理解争议)
    * [举列说明](#举列说明)
  * [Base理论](#base理论)
* [业内解决方案](#业内解决方案)
* [2PC](#2pc)
  * [缺点](#缺点)
  * [**预提交阶段**](#预提交阶段)
  * [提交阶段](#提交阶段)
* [3PC](#3pc)
* [saga](#saga)
* [TCC](#tcc)
* [消息事务-本地消息表（最终一致性）](#消息事务-本地消息表最终一致性)
* [参考资料](#参考资料)


# 分布式事务的产生

考虑支付重构的时候，自然想到原本属于一个本地事务中的处理，现在要跨应用了要怎么处理。拿充值订单举个栗子吧，

假设：

1. 原本订单模块和账户模块是放在一起的，现在需要做服务拆分，拆分成订单服务，账户服务。

2. 原本收到充值回调后，可以将修改订单状态和增加金币放在一个mysql事务中完成的，

3. 但是呢，因为服务拆分了，就面临着需要协调2个服务才能完成这个事务





# 分布式事务基础



## 分布式CAP怎么理解（争议）


+ Partition-tolerance分区可容忍性 (必须存在)

  > 强调是：分区后系统要能提供可用服务！！

  分区容错性P其实就是每个服务都会部署多个节点，这样就可以保证此服务的一个节点挂了之后，此服务的其他节点依然可以响应 

+ Consistency一致性

  数据一致性，对于分布式项目来说,要保证数据的一致性，目前分布式项目的分为强一致性(2PC)和消息最终一致性(消息队列：记录和补偿)

  

   在满足了分区容错性P后，想要满足一致性C，一个服务的多个节点之间就必须进行数据复制达到数据一致之后再返回给调用者响应，然而在多个节点数据复制的过程中，可能节点之间会出现网络等问题使得数据复制阻塞或失败导致响应超时，服务调用失败，这就失去了系统的可用性A。 

  

+ Availability：可用性

  > 高性能？

  如果不强制满足强一致性，那在服务被调用的时候不用管数据复制的问题，直接返回响应，这就满足了可用性，但是由于此服务的多个节点数据可能没有完成复制，节点数据可能不一致，这就失去了系统的一致性。 



### 举列说明



理解CAP理论最简单的方式是想象两个**副本**处于分区两侧，即两个副本之间的网络断开，不能通信。

- 如果允许其中一个副本更新，则会导致数据不一致，即丧失了C性质。
- 如果为了保证一致性，将分区某一侧的副本设置为不可用，那么又丧失了A性质。
- 除非两个副本可以**互相通信**，才能既保证C又保证A，这又会导致**丧失P性质**。

一般来说使用网络通信的分布式系统，无法舍弃P性质，那么就只能在一致性和可用性上做一个艰难的选择。

> Q：一般来说使用网络通信的分布式系统，无法舍弃P性质
>
> A: 怕部分不可用影响整体不可用，舍弃了P,就像是单体了。






## Base理论

BASE 理论， 是对CAP中AP的一个扩展，对于我们的业务系统，我们考虑牺牲一致性来换取系统的可用性和分区容错性。BASE是Basically Available(基本可用)，Soft state（软状态）,和 Eventually consistent（最终一致性）三个短语的缩写。

- 基本可用是指，通过支持局部故障而不是系统全局故障来实现的；
- Soft State表示状态可以有一段时间不同步；
- 最终一致，最终数据是一致的就可以了，而不是实时保持强一致。

# 业内解决方案



# 2PC



> # XA
>
> XA是X/Open组织提出的一个分布式事务的规范，其定义了一个分布式事务的处理模型——DTP。在DTP中定义了三个组件：
> Application Program（AP）：应用程序，即业务层，它定义了事务的边界，以及构成该事务的特定操作；
> Resource Manager（RM）：资源管理器，可以理解为一个DBMS系统，或者消息服务器管理系统；
> Transaction Manager（TM）：事务管理器，负责协调和管理事务；



基于 XA 协议实现的分布式事务，XA 协议中分为两部分：事务管理器和本地资源管理器。其中本地资源管理器往往由数据库实现，比如 Oracle、MYSQL 这些数据库都实现了 XA 接口，而事务管理器则作为一个全局的调度者。



1. 在XA规范中，数据库充当RM角色，应用需要充当TM的角色，**即生成全局的txId**，调用XAResource接口，把多个本地事务协调为全局统一的分布式事务。
2. 2PC模型中，**在prepare阶段需要等待所有参与子事务的反馈，因此可能造成数据库资源锁定时间过长，不适合并发高以及子事务生命周长较长的业务场景**。
3. 两阶段提交（2PC），对业务侵⼊很小，<font color=red>它最⼤的优势就是对使⽤⽅透明，用户可以像使⽤本地事务⼀样使⽤基于 XA 协议的分布式事务，能够严格保障事务 ACID 特性。</font>

![](.images/image-20210716095826687.png)



## 缺点

可2PC的缺点也是显而易见，它是一个强一致性的同步阻塞协议，事务执⾏过程中需要将所需资源全部锁定，也就是俗称的刚性事务。所以它比较适⽤于执⾏时间确定的短事务，整体性能比较差。



> 2PC只有协调者有超时机制，一旦协调者挂了，参与者提交资源就会被锁住

<font color=red>一旦事务协调者宕机或者发生网络抖动，会让参与者一直处于锁定资源的状态或者只有一部分参与者提交成功，导致数据的不一致。</font>因此，在⾼并发性能⾄上的场景中，基于 XA 协议的分布式事务并不是最佳选择。

![](.images/image-20210716100002409.png)

## **预提交阶段**

这是两阶段提交协议的第一个阶段，分布式事务处理系统咨询各个资源管理器是否可以提交本地事务，各个资源管理器会把这个咨询过程写入日志，以便进行回滚或提交。

当一个数据库接收到咨询后，它会将需要执行的操作写入日志，禁止其他写入操作（锁定资源）。

> 锁定什么资源?

如果分布式事务中某数据库预提交失败或提交失败，那该数据库会根据日志进行自身的操作回滚，并解锁。

## 提交阶段

分布式事务处理系统对各个资源管理器下达提交/回滚的指令，使整个分布式事务结束。

当一个数据库接受到提交/回滚指令时，它将根据第一阶段的日志进行提交/回滚处理。

两阶段提交协议可以在数据库层面通过驱动支持，也可以在应用框架中按照其原理进行设计实现。



# 3PC

三段提交（3PC）是二阶段提交（2PC）的一种改进版本 ，为解决两阶段提交协议的阻塞问题，上边提到两段提交，当协调者崩溃时，参与者不能做出最后的选择，就会一直保持阻塞锁定资源。



+ 2PC中只有协调者有超时机制，<font color=red>3PC在协调者和参与者中都引入了超时机制，协调者出现故障后，参与者就不会一直阻塞</font>。

+ 而且在第一阶段和第二阶段中又插入了一个准备阶段（如下图，看着有点啰嗦），保证了在最后提交阶段之前各参与节点的状态是一致的。

  > 就是多问一次。


![](.images/image-20210717140417745.png)
虽然 3PC 用超时机制，解决了协调者故障后参与者的阻塞问题，<font color=red>但与此同时却多了一次网络通信</font>，性能上反而变得更差，也不太推荐。







# saga

saga的提出，最早是为了解决可能会长时间运行的分布式事务（long-running process）的问题。所谓long-running的分布式事务，是指那些企业业务流程，需要跨应用、跨企业来完成某个事务，甚至在事务流程中还需要有手工操作的参与，这类事务的完成时间可能以分计，以小时计，甚至可能以天计。这类事务如果按照事务的ACID的要求去设计，势必造成系统的可用性大大的降低。试想一个由两台服务器一起参与的事务，服务器A发起事务，服务器B参与事务，B的事务需要人工参与，所以处理时间可能很长。如果按照ACID的原则，要保持事务的隔离性、一致性，服务器A中发起的事务中使用到的事务资源将会被锁定，不允许其他应用访问到事务过程中的中间结果，直到整个事务被提交或者回滚。这就造成事务A中的资源被长时间锁定，系统的可用性将不可接受。

而**saga，则是一种基于补偿的消息驱动的用于解决long-running process的一种解决方案。目标是为了在确保系统高可用的前提下尽量确保数据的一致性。** 还是上面的例子，如果用saga来实现，那就是这样的流程：服务器A的事务先执行，如果执行顺利，那么事务A就先行提交；如果提交成功，那么就开始执行事务B，如果事务B也执行顺利，则事务B也提交，整个事务就算完成。但是如果事务B执行失败，那事务B本身需要回滚，这时因为事务A已经提交，所以需要执行一个补偿操作，将已经提交的事务A执行的操作作反操作，恢复到未执行前事务A的状态。这样的基于消息驱动的实现思路，就是saga。我们可以看出，saga是牺牲了数据的强一致性，仅仅实现了最终一致性，但是提高了系统整体的可用性。



# TCC

所谓的TCC编程模式，也是两阶段提交的一个变种，不同的是TCC为在业务层编写代码实现的两阶段提交。<font color=red>TCC分别指Try、Confirm、Cancel，一个业务操作要对应的写这三个方法。</font>

以下单扣库存为例，Try阶段去占库存，Confirm阶段则实际扣库存，如果库存扣减失败Cancel阶段进行回滚，释放库存。

TCC 不存在资源阻塞的问题，因为每个方法都直接进行事务的提交，一旦出现异常通过则Cancel来进行回滚补偿，这也就是常说的<font color=red>补偿性事务</font>。

原本一个方法，现在却需要三个方法来支持，可以看到 TCC 对业务的侵入性很强，而且这种模式并不能很好地被复用，会导致开发量激增。还要考虑到网络波动等原因，为保证请求一定送达都会有重试机制，所以考虑到接口的幂等性。



#  消息事务-本地消息表（最终一致性）




> 最终一致性，主要是用“记录”和“补偿”的方式。在做所有的不确定的事情之前，先把事情记录下来，然后去做不确定的事情，结果可能是：成功、失败或是不确定，“不确定”（例如超时等）可以等价为失败。
>
> 成功就可以把记录的东西清理掉了，对于失败和不确定，可以依靠定时任务等方式把所有失败的事情重新搞一遍，直到成功为止。
>
>  回到刚才的例子，**系统在A扣钱成功的情况下**，**把要给B“通知”这件事记录在库里**（为了保证最高的可靠性可以把通知B系统加钱和扣钱成功这两件事维护在一个本地事务里），通知成功则删除这条记录，通知失败或不确定则依靠定时任务补偿性地通知我们，直到我们把状态更新成正确的为止。 整个这个模型依然可以基于RPC来做，但可以抽象成一个统一的模型，基于消息队列来做一个“企业总线”。 **具体来说，本地事务维护业务变化和通知消息**，一起落地（失败则一起回滚），然后RPC到达broker，在broker成功落地后，RPC返回成功，本地消息可以删除。否则本地消息一直靠定时任务轮询不断重发，这样就保证了消息可靠落地broker。 broker往consumer发送消息的过程类似，一直发送消息，直到consumer发送消费成功确认。 我们先不理会重复消息的问题，通过两次消息落地加补偿，下游是一定可以收到消息的。然后依赖状态机版本号等方式做判重，更新自己的业务，就实现了最终一致性。






消息事务其实就是基于<font color=red>消息中间件的两阶段提交，将本地事务和发消息放在同一个事务里，保证本地操作和发送消息同时成功</font>>。 下单扣库存原理图：

<div align=left>
	<img src=".images/3203312832-41b4499311d87aff_fix732.png" >
</div>


1. 订单系统向MQ发送一条预备扣减库存消息，MQ保存预备消息并返回成功ACK

   > 类似2PC的预提交，根据这里的消息，进行提交或者回滚

2. 接收到预备消息执行成功ACK，订单系统执行本地下单操作，为防止消息发送成功而本地事务失败，订单系统会实现MQ的回调接口，其内不断的检查本地事务是否执行成功，如果失败则rollback回滚预备消息；成功则对消息进行最终commit提交。

3. 库存系统消费扣减库存消息，执行本地事务，如果扣减失败，消息会重新投，一旦超出重试次数，则本地表持久化失败消息，并启动定时任务做补偿。

   > 如果扣减失败，通过MQ通知到订单系统，扣减失败。

基于消息中间件的两阶段提交方案，<font color=red>通常用在高并发场景下使用，牺牲数据的强一致性换取性能的大幅提升</font>，不过实现这种方式的成本和复杂度是比较高的，还要看实际业务情况。



**对于消息发送方：**

- 首先需要有一个消息表，记录着消息状态相关信息。
- 业务数据和消息表在同一个数据库，即要保证它俩在同一个本地事务。
- 在本地事务中处理完业务数据和写消息表操作后，通过写消息到MQ消息队列。
- 消息会发到消息消费方，如果发送失败，即进行重试。

**消息消费方：**

- 处理消息队列中的消息，完成自己的业务逻辑。
- 此时如果本地事务处理成功，则表明已经处理成功了。
- 如果本地事务处理失败，那么就会重试执行。
- 如果是业务上面的失败，给消息生产方发送一个业务补偿消息，通知进行回滚等操作。

生产方和消费方定时扫描本地消息表，把还没处理完成的消息或者失败的消息再发送一遍。如果有靠谱的自动对账补账逻辑，这种方案还是非常实用的。






# 参考资料

+ https://segmentfault.com/a/1190000038424744
+ https://mp.weixin.qq.com/s/LqoWAT4cz4KcdaTzEP3iTA


