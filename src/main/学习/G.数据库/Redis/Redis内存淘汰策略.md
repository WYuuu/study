# Table of Contents

* [**近似LRU算法**](#近似lru算法)
* [**Redis懒惰删除key的原因**](#redis懒惰删除key的原因)
* [**从库过期策略**](#从库过期策略)
* [**拓展问题**](#拓展问题)


需要先了解下Redis的过期策略。

定时删除：是在设置键的过期时间的同时，创建一个定时器，让定时器在键的过期时间来临时，立即执行对键的删除操作；

定期删除：redis默认是每隔 100ms就随机抽取一些设置了过期时间的key，检查其是否过期，如果过期就删除。注意这里是随机抽取的。为什么要随机呢？你想一想假如 redis 存了几十万个 key ，每隔100ms就遍历所有的设置过期时间的 key 的话，就会给 CPU 带来很大的负载。

惰性删除：所谓惰性策略就是在客户端访问这个key的时候，redis对key的过期时间进行检查，如果过期了就立即删除，不会给你返回任何东西。

总结：定期删除是集中处理，惰性删除是零散处理。 **Redis过期键采用的是定期删除+惰性删除二者结合**的方式进行删除的。

> Q:为什么有了过期策略还需要内存淘汰策略? A:定期和惰性会存在Key没有被删除的场景



# **近似LRU算法**

1、Redis采用近似LRU算法进行缓存淘汰，不使用LRU算法的原因是需要消耗大量的内存且要对现有的数据结构进行较大的改造；

2、Redis近似LRU算法的实现，每个key增加了一个长度24位的字段用于存放最后一次访问的时间戳

3、Redis LRU淘汰采用懒惰处理且只有懒惰处理，当Redis执行写操作时如果使用的内存超过maxmemory的配置时就会执行一次LRU淘汰算法，随机采样出5个（可以配置）key，然后删除最旧的key，如果淘汰后的内存使用量还是超过了maxmemory就继续随机采样直到内存低于maxmemory为止（采样策略使用maxmemory-policy：volatile-lru、volatile-ttl、volatile-random、noeviction、all-lru、all-random，采样数量使用maxmemory_samples）

4、采样数量越大近似LRU算法的效果越严格接近LRU算法，Redis3.0优化近似LRU算法新增了淘汰池；淘汰池是一个数组，它的大小是maxmemory_samples【配置的key，上文的5】，在每次淘汰循环中新随机出来的key列表会和淘汰池中的key列表进行融合，淘汰掉最旧的一个key之后保留剩余较旧的key列表放入淘汰池中留待下一个循环

**Redis不是单线程的**

Redis内部实际上不只有一个主线程，还有几个异步线程专门用来处理耗时操作

# **Redis懒惰删除key的原因**

1、普通的del指令会直接释放对象内存且非常迅速，但是如果删除的是一个非常大的对象，就会导致单线程卡顿

2、Redis4.0之后引入了unlink指令，能对删除操作进行懒处理，先断开该key，然后丢给后台线程来异步回收内存；当unlink指令发出时，相当于把大树中的一个树枝别断了，然后扔到旁边的火堆里焚烧（异步线程池）；树枝离开大树的一瞬间就再也无法被主线程中的指令访问到了，因为主线程只会沿着这颗大树来访问





> 注意！不管是过期策略还是内存淘汰策略，总是会有Key无法被删除，所以要避免使用 big key。

> 为什么不维护队列？

1. 内存占用问题
2. LRU链表删除会带来内存开销



# **从库过期策略**

1、从库不会主动进行过期扫描，从库对过期的处理是被动的；主库在key到期时会在AOF文件里增加一条del指令同步到所有的从库，从库通过执行这条del指令来删除过期的key

2、指令同步是异步进行的，**所以主库过期的key的del指令没有及时同步到从库的话会导致主从不一致的情况**。



从库可能造成的问题

+ 拉取过期数据

  + ​	跟 Redis 的版本有关系，Redis 3.2 之前版本，读从库并不会判断数据是否过期，所以有可能返回过期数据

  + 跟过期时间的设置方式有关系，我们一般采用 `EXPIRE 和 PEXPIRE`，表示从执行命令那个时刻开始，往后延长 ttl 时间。严重依赖于 `开始时间` 从什么时候算起。

    > 可以采用Redis的另外两个命令，`EXPIREAT 和 PEXPIREAT`，相对简单，表示过期时间为一个具体的时间点。避免了对`开始时间`从什么时候算起的依赖。

+ 数据一致性问题

  + 网络延迟

  + 从库已经收到主库的命令，由于是单线程执行，前面正在处理一些耗时的命令（如：pipeline批处理），无法及时同步执行。

    > 1、主从服务器尽量部署在同一个机房，并保持服务器间的网络良好通畅
    >
    > 2、监控主从库间的同步进度,超过设定的值，直接读主库，然后在同步从库

  ​	





# **拓展问题**

“过期key扫描不是有 25ms 的时间上限了么，怎么会导致卡顿呢”？这里打个比方，假如有 101 个客户端同时将请求发过来了，然后前 100 个请求的执行时间都是 25ms，那么第 101 个指令需要等待多久才能执行？2500ms，这个就是客户端的卡顿时间，是由服务器不间断的小卡顿积少成多导致的。

所以如果有大批key过期，需要给过期时间设置一个随机范围，而不要在同一时间过期
